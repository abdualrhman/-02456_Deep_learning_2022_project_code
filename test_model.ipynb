{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model on testing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following script, we will test the saved model on a test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from DataModel import DataModel, TensorDataSet, TensorTabDataSet\n",
    "from sklearn import metrics\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "\n",
    "from tab_transformer_pytorch import TabTransformer, FTTransformer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test FT-Transformer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoding_type = 'label'\n",
    "cols_to_ohe = ['priority', 'deck_on_vessel', 'is_reefer', 'is_hazardous', 'unitype_id']\n",
    "dm = DataModel(encoding_type=data_encoding_type, cols_to_ohe=cols_to_ohe)\n",
    "df = dm.get_df()\n",
    "X,y = dm.get_inputs_targets()\n",
    "\n",
    "def get_cols_unique_num():\n",
    "    uniques = []\n",
    "    for ind, i in enumerate(X.columns):\n",
    "        if ind == 0 or ind == 1: continue\n",
    "        # print(len(X[i].unique()))\n",
    "        uniques.append(len(X[i].unique()))\n",
    "    return tuple(uniques)\n",
    "print(get_cols_unique_num())\n",
    "unique_cat_num_tuple = get_cols_unique_num()\n",
    "unique_cat_num_tuple = get_cols_unique_num()\n",
    "\n",
    "model = FTTransformer(\n",
    "    categories = unique_cat_num_tuple,\n",
    "    num_continuous = 2,          \n",
    "    dim = 64,                     \n",
    "    dim_out = 1,                  \n",
    "    depth = 6,                    \n",
    "    heads = 8,                    \n",
    "    attn_dropout = 0.2,           \n",
    "    ff_dropout = 0.1              \n",
    ")\n",
    "device = torch.device('cpu')  # use cuda or cpu\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved model\n",
    "replace the path with saved model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"/Users/abdulrahman/Documents/DTU/deep-learning/02456_Deep_learning_2022_project_code/model_20230105_012058_0\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "ts_tab_ds = TensorTabDataSet(data_type='test',normalize_num=False, encoding_type=data_encoding_type, cols_to_ohe=cols_to_ohe)\n",
    "\n",
    "test_tab_loader =  DataLoader(ts_tab_ds, batch_size=batch_size)\n",
    "\n",
    "test_results = pd.DataFrame({'pred':[], 'target':[]})\n",
    "\n",
    "test_accuracy = []\n",
    "pred_list=[]\n",
    "targ_list=[]\n",
    "for i ,data in enumerate(test_tab_loader):\n",
    "    model.train(False)\n",
    "    vinputs, vtargets = data\n",
    "    vcat_inputs, vnum_inputs = vinputs[0], vinputs[1]\n",
    "    vtargets = vtargets.type(torch.FloatTensor)\n",
    "    vtargets = vtargets.unsqueeze(dim=1)\n",
    "    pred = model(vcat_inputs, vnum_inputs)\n",
    "    pred_list.extend(pred.cpu().detach().numpy().squeeze())\n",
    "    targ_list.extend(vtargets.cpu().detach().numpy().squeeze())\n",
    "    test_accuracy.append(metrics.r2_score(vtargets.cpu().detach().numpy().squeeze(), pred.cpu().detach().numpy().squeeze()))\n",
    "plt.plot(test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test FNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FFModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(FFModel, self).__init__()  \n",
    "        self.input_size =input_size\n",
    "        self.l1=nn.Linear(self.input_size, self.input_size*2)\n",
    "        self.l2=nn.Linear(self.input_size*2, self.input_size*10)\n",
    "        self.l3=nn.Linear(self.input_size*10, self.input_size*20)\n",
    "        self.l4=nn.Linear(self.input_size*20, self.input_size*50)\n",
    "        self.l5=nn.Linear(self.input_size*50, self.input_size*55)\n",
    "        self.l6=nn.Linear(self.input_size*55, 1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.30)\n",
    "    def forward(self, x):\n",
    "        out=self.l1(x)\n",
    "        out=self.relu(out)\n",
    "        self.dropout(out)\n",
    "        out=self.l2(out)\n",
    "        out=self.relu(out)\n",
    "        self.dropout(out)\n",
    "        out=self.l3(out)\n",
    "        out=self.relu(out)\n",
    "        self.dropout(out)\n",
    "        out=self.l4(out)\n",
    "        out=self.relu(out)\n",
    "        self.dropout(out)\n",
    "        out=self.l5(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.l6(out)\n",
    "        return out\n",
    "# encode_type = ''\n",
    "# cols_to_label_encode=['place_on_board']\n",
    "data_encoding_type = 'label'\n",
    "cols_to_ohe = ['priority', 'deck_on_vessel', 'is_reefer', 'is_hazardous', 'unitype_id']\n",
    "dm = DataModel(encoding_type=data_encoding_type, normalize_num=False, cols_to_ohe=cols_to_ohe)\n",
    "df = dm.get_df()\n",
    "input_size = dm.get_inputs_targets()[0].shape[1]\n",
    "model = FFModel(input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load saved model\n",
    "replace the path with saved model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"PATH\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 64\n",
    "ts_ff_ds = TensorDataSet(data_type='test',normalize_num=False, encoding_type=data_encoding_type, cols_to_ohe=cols_to_ohe)\n",
    "\n",
    "test_ff_loader =  DataLoader(ts_ff_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ff_results = pd.DataFrame({'pred':[], 'target':[]})\n",
    "\n",
    "test_ff_accuracy = []\n",
    "pred_ff_list=[]\n",
    "targ_ff_list=[]\n",
    "for i ,data in enumerate(test_ff_loader):\n",
    "    model.train(False)\n",
    "    vinputs, vtargets = data\n",
    "    # vcat_inputs, vnum_inputs = vinputs[0], vinputs[1]\n",
    "    vtargets = vtargets.type(torch.FloatTensor)\n",
    "    vtargets = vtargets.unsqueeze(dim=1)\n",
    "    pred = model(vinputs)\n",
    "    pred_ff_list.extend(pred.cpu().detach().numpy().squeeze())\n",
    "    targ_ff_list.extend(vtargets.cpu().detach().numpy().squeeze())\n",
    "    # print(\"vtargets.cpu().detach().numpy().squeeze()\")\n",
    "\n",
    "    # if i == 0:\n",
    "    #     break\n",
    "    test_ff_accuracy.append(metrics.r2_score(vtargets.cpu().detach().numpy().squeeze(), pred.cpu().detach().numpy().squeeze()))\n",
    "plt.plot(test_ff_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d685bfd7114377445cb2c23cc6bfca7f1f2544957139cb4a27ccab868339e3e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
